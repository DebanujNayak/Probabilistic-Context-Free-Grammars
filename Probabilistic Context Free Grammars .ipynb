{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Context Free Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are PCFGs ? A brief introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The simplest augmentation of the context-free grammar is the Probabilistic Context Free Grammar (PCFG), <br/><br/>It is also known as the Stochastic Context Free Grammar (SCFG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall that a context-free grammar G is defined by four parameters ($N ,\\sum , R , S$) <br/><br/>A probabilistic context-free grammar is also defined by four parameters, with a slight augmentation to each of the rules in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. $N$ - the set of non terminals <br/><br/>2. $\\sum$ - The set of terminal symbols <br/><br/>3. $R$ - A set of rules of production. Each rule is associated with Some probability<br/><br/>4. $S$ - Start Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each rule has a probabilty assigned to it. <br/><br/> For example $ A$  $- > B$ $[p]$<br/><br/>Here $p$ is the probability that $A$ will be expanded to $B$. <br/><br/> Thus $P( A$ $- > B | A ) = p$<br/><br/> These associated probabilities are learned from a treebank i.e. a corpus of already parsed sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Disambiguation using PCFGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One sentence consists of many words where each word can have multiple senses.<br/><br/> Sentence disambiguation helps us too decide which is the correct sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCFGs can be used to perform sentence disambiguation. <br/><br/>The idea is for a given sentence , we will use the PCFG and the CKY algorithm to generate all parse trees for that sentence. <br/><br/>Calculate the probability of each parse tree and then select that one which has the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus, out of all parse trees with a yield of S, the disambiguation algorithm picks the parse tree $\\hat{T}$ that is most probable given S : <br/><br/> $ \\hat{T}(S) =$ $argmax$ $P(T|S)$<br/><br/> However by definition probability $P(T|S)$ can be rewritten as $P(T,S)$ $/$ $P(S)$, thus leading to<br/><br/> $ \\hat{T}(S) =$ $argmax$ $\\frac{P(T,S)}{P(S)}$<br/><br/> However $P(S)$ is a constant , thus we get <br/><br/>  $ \\hat{T}(S) =$ $argmax$ $P(T,S)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the sections below , we will see an a Python implementation of PCFGs and the CKY algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import random\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from turtle import *\n",
    "\n",
    "class DefaultDict (dict):\n",
    "    def __init__(self, default):\n",
    "        self.default = default\n",
    "    def __getitem__(self, key):\n",
    "        if key in self: return self.get(key)\n",
    "        return self.setdefault(key, copy.deepcopy(self.default))\n",
    "    def sorted(self, rev=True):\n",
    "        counts = [ (c,w) for w,c in self.items() ]\n",
    "        counts.sort(reverse=rev)\n",
    "        return counts\n",
    "\n",
    "class CountingDict (DefaultDict):\n",
    "    def __init__(self):\n",
    "        DefaultDict.__init__(self, 0)\n",
    "        \n",
    "def conv_2_dict(**args): \n",
    "    # This function returns a dictionary with argument names as the keys, \n",
    "    # and the argument values as the key values.\n",
    "    return args\n",
    "        \n",
    "def mappend(fn, list):\n",
    "    # Append the results of calling fn on each element of list.\n",
    "    return reduce(lambda x,y: x+y, map(fn, list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us take a Probabilistic Context Free Grammar in Chomsky Normal Form  (CNF)\n",
    "#### We will encode the grammar into a Python dictionary as follows :-  <br/><br/> NP -> DetN [ p1 ]<br/><br/> NP -> N  [ p2 ]<br/><br/>  NP -> N PP [ p3 ]<br/><br/> will become NP = { ( 'Det' , 'N' ) : p1 , ( 'N' ) : p2 , ( 'N', 'PP' ) : p3 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grammar = conv_2_dict(\n",
    "        #start symbol\n",
    "        S = {('NPPL','NVPL'):.25, ('NPS','NVS'):.3, ('NPPL','VPPPL'):.2, ('NPS','VPPS'):.25},\n",
    "    \n",
    "        #noun phrase \n",
    "        NPPL = {('DetP', 'ADJNPL'):.4, ('DetP', 'NPL'):.6},\n",
    "        NPS = {('DetS', 'ADJNS'):.3, ('DetS', 'NS'):.70},\n",
    "    \n",
    "        #adj plural and singular\n",
    "        ADJNS = {('J', 'NS'):1},\n",
    "        ADJNPL = {('J', 'NPL'):1},\n",
    "    \n",
    "        #verb singular/plural with noun phrase singular/plural\n",
    "        NVS = {('VS','NPS'):1},\n",
    "        NVPL = {('VPL','NPPL'):1},\n",
    "    \n",
    "        #singular/purple verb and noun with singular/plural prep phrase\n",
    "        VPPPL = {('NVPL', 'PPPL'):.8, ('NVPL', 'PPS'):.2},\n",
    "        VPPS = {('NVS', 'PPS'):.8, ('NVS', 'PPPL'):.1},\n",
    "    \n",
    "        #prep phrase\n",
    "        PPS = {('P', 'NPS'):1},\n",
    "        PPPL = {('P', 'NPPL'):1},\n",
    "    \n",
    "        #verbs that should be followed with \"with\"\n",
    "        EDP = {('ED','P'):1},\n",
    "    \n",
    "        #training data\n",
    "        DetS = {'the':.36, 'a':.65},\n",
    "        DetP = {'the':1},\n",
    "        P = {'with':1},\n",
    "        J = {'red':.5, 'big':.5},\n",
    "        NS = {'dog':float(1)/3, 'ball':float(1)/3, 'light':float(1/3)},\n",
    "        NPL = {'dogs':.5, 'pickles':.5},\n",
    "        VS = {'pickles':.25, 'sees':.25, 'liked':.25,'EDP':.25},\n",
    "        VPL = {'see':float(1)/3, 'liked':float(1)/3, 'light':float(1)/3, 'EDP':1},\n",
    "        ED = {'slept':1}\n",
    "        )\n",
    "\n",
    "#print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now using the below function we can print the grammar in the normal human readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S  ->  ('NPPL', 'NVPL') [ 0.25 ]\n",
      "S  ->  ('NPS', 'NVS') [ 0.3 ]\n",
      "S  ->  ('NPPL', 'VPPPL') [ 0.2 ]\n",
      "S  ->  ('NPS', 'VPPS') [ 0.25 ]\n",
      "NPPL  ->  ('DetP', 'ADJNPL') [ 0.4 ]\n",
      "NPPL  ->  ('DetP', 'NPL') [ 0.6 ]\n",
      "NPS  ->  ('DetS', 'ADJNS') [ 0.3 ]\n",
      "NPS  ->  ('DetS', 'NS') [ 0.7 ]\n",
      "ADJNS  ->  ('J', 'NS') [ 1 ]\n",
      "ADJNPL  ->  ('J', 'NPL') [ 1 ]\n",
      "NVS  ->  ('VS', 'NPS') [ 1 ]\n",
      "NVPL  ->  ('VPL', 'NPPL') [ 1 ]\n",
      "VPPPL  ->  ('NVPL', 'PPPL') [ 0.8 ]\n",
      "VPPPL  ->  ('NVPL', 'PPS') [ 0.2 ]\n",
      "VPPS  ->  ('NVS', 'PPS') [ 0.8 ]\n",
      "VPPS  ->  ('NVS', 'PPPL') [ 0.1 ]\n",
      "PPS  ->  ('P', 'NPS') [ 1 ]\n",
      "PPPL  ->  ('P', 'NPPL') [ 1 ]\n",
      "EDP  ->  ('ED', 'P') [ 1 ]\n",
      "DetS  ->  the [ 0.36 ]\n",
      "DetS  ->  a [ 0.65 ]\n",
      "DetP  ->  the [ 1 ]\n",
      "P  ->  with [ 1 ]\n",
      "J  ->  red [ 0.5 ]\n",
      "J  ->  big [ 0.5 ]\n",
      "NS  ->  dog [ 0.3333333333333333 ]\n",
      "NS  ->  ball [ 0.3333333333333333 ]\n",
      "NS  ->  light [ 0.3333333333333333 ]\n",
      "NPL  ->  dogs [ 0.5 ]\n",
      "NPL  ->  pickles [ 0.5 ]\n",
      "VS  ->  pickles [ 0.25 ]\n",
      "VS  ->  sees [ 0.25 ]\n",
      "VS  ->  liked [ 0.25 ]\n",
      "VS  ->  EDP [ 0.25 ]\n",
      "VPL  ->  see [ 0.3333333333333333 ]\n",
      "VPL  ->  liked [ 0.3333333333333333 ]\n",
      "VPL  ->  light [ 0.3333333333333333 ]\n",
      "VPL  ->  EDP [ 1 ]\n",
      "ED  ->  slept [ 1 ]\n"
     ]
    }
   ],
   "source": [
    "# Prints the grammar in human readable form\n",
    "def print_grammar(grammar):\n",
    "    for i in grammar.items():\n",
    "        left = i[0]\n",
    "        prods = i[1]\n",
    "        for j in prods.keys():\n",
    "            print(left,\" -> \",j,\"[\",prods[j],\"]\")\n",
    "        \n",
    "print_grammar(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Probabilistic CKY parsing algorithm\n",
    "#### The parsing problem for PCFGs is to produce the most-likely parse $\\hat{T}$ for a given sentence $S$, that is,<br/><br/>$\\hat{T}(S) =$ $argmax$ $P(T)$<br/><br/>Most modern probabilistic parsers are based on the Probabilistic probabilistic CKY algorithm.<br/><br/>As with the CKY algorithm, we assume for the probabilistic CKY algorithm that the PCFG is in Chomsky normal form.\n",
    "#### Some helper functions for writing the CKY algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Argument is a list containing the rhs of some rule; return all possible lhs's\"\n",
    "def list_of_producers(output):\n",
    "    results = []\n",
    "    for (lhs,rhss) in grammar.items():\n",
    "        for rhs in rhss:\n",
    "            if rhs == output:\n",
    "                results.append(lhs)\n",
    "                \n",
    "    return results\n",
    "\n",
    "# Print the CKY table \n",
    "def print_CKY_table(table,wordlist):\n",
    "    tab=[]\n",
    "    for i in range(len(table)):\n",
    "        tab.append(table[i][1:])\n",
    "    data = np.array(tab)\n",
    "    df = pandas.DataFrame(data,[0]*len(table),wordlist)\n",
    "    print(tabulate(df, tablefmt=\"markdown\", headers=\"keys\"))\n",
    "\n",
    "\n",
    "# Creates in the parse tree in the form of a nested tuple\n",
    "def make_tree(x, trace, i, j, X):\n",
    "    n = j - i\n",
    "    if n == 1:\n",
    "        return (X, x[i])\n",
    "    else:\n",
    "        Y, Z, s = trace[i, j, X]\n",
    "        return (X, make_tree(x, trace, i, s, Y),\n",
    "                   make_tree(x, trace, s, j, Z))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CKY parse function , returns True if the argument sentence is in the grammar; returns False otherwise <br/><br/>It also outputs the table used in the Probabilistic CKY algorithm and also displays the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CKY Algorithm Table\n",
      "\n",
      "    the               pickles        light          the               dogs\n",
      "--  ----------------  -------------  -------------  ----------------  --------\n",
      " 0  ['DetS', 'DetP']  ['NPPL']       []             []                ['S']\n",
      " 0  []                ['NPL', 'VS']  []             []                []\n",
      " 0  []                []             ['NS', 'VPL']  []                ['NVPL']\n",
      " 0  []                []             []             ['DetS', 'DetP']  ['NPPL']\n",
      " 0  []                []             []             []                ['NPL']\n",
      "\n",
      "The Parse Tree\n",
      "\n",
      "('S', ('NPPL', ('DetP', 'the'), ('NPL', 'pickles')), ('NVPL', ('VPL', 'light'), ('NPPL', ('DetP', 'the'), ('NPL', 'dogs'))))\n"
     ]
    }
   ],
   "source": [
    "def CKY_parse(sentence):\n",
    "   \n",
    "    global grammar\n",
    "    \n",
    "    # Create the table; index j for rows, i for columns\n",
    "    length = len(sentence)\n",
    "    table = [None] * (length)\n",
    "    table2 = DefaultDict(float)\n",
    "    trace = {}\n",
    "\n",
    "    for j in range(length):\n",
    "        table[j] = [None] * (length+1)\n",
    "        for i in range(length+1):\n",
    "            table[j][i] = []\n",
    "    \n",
    "    \n",
    "    # Fill the diagonal of the table with the POS tag of the words\n",
    "    for k in range(1,length+1):\n",
    "        results = list_of_producers(sentence[k-1])\n",
    "        for item in results:\n",
    "            list = (item, sentence[k-1])\n",
    "            prob = grammar[item][sentence[k-1]]\n",
    "            #print grammar[item][sentence[k-1]]\n",
    "            table2[k-1,k, item] = prob\n",
    "        table[k-1][k].extend(results)\n",
    "\n",
    "    #core CKY part\n",
    "    for width in range(2,length+1): \n",
    "        for start in range(0,length+1-width): \n",
    "            end = start + width \n",
    "            for mid in range (start, end): \n",
    "                max_score = 0\n",
    "                args = None\n",
    "                for x in table[start][mid]: \n",
    "                    for y in table[mid][end]:\n",
    "                        #print x,y\n",
    "                        results = list_of_producers((x,y))\n",
    "                        for item in results:\n",
    "                            prob1 = grammar[item][(x,y)]\n",
    "                            prob2 = prob1 * table2[start, mid, x] * table2[mid, end, y]\n",
    "                            checkme = start, end, item\n",
    "                            if checkme in table2:\n",
    "                                if prob2 > table2[start, end, item]:\n",
    "                                    table2[start, end, item] = prob2\n",
    "                            else:\n",
    "                                table2[start, end, item] = prob2\n",
    "                            args2 = x, y, mid\n",
    "                            if args2 in trace:\n",
    "                                if prob2 > table2[start, end, item]:\n",
    "                                    args = x, y, mid\n",
    "                                    trace[start, end, item] = args\n",
    "                            else:\n",
    "                                args = x, y, mid\n",
    "                                trace[start, end, item] = args\n",
    "                            trace[start, end, item] = args\n",
    "                            if item not in table[start][end]:\n",
    "                                table[start][end].append(item)\n",
    "\n",
    "\n",
    "    # Print the table\n",
    "    print (\"The CKY Algorithm Table\\n\")\n",
    "    print_CKY_table(table, sentence)\n",
    "\n",
    "\n",
    "    print (\"\\nThe Parse Tree\\n\")\n",
    "    if table2[0, length-1, 'S']:\n",
    "        mytree = make_tree(sentence, trace, 0, length, 'S')\n",
    "        \n",
    "    print(mytree)\n",
    "      \n",
    "CKY_parse('the pickles light the dogs'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with PCFGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While probabilistic context-free grammars are a natural extension to context-free grammars, they have two main problems as probability estimators :- <br/><br/> 1. CFG rules impose an independence assumption on probabilities, resulting in poor modeling of structural dependencies across the parse tree. <br/><br/>  2. CFG rules donâ€™t model syntactic facts about specific words, leading to problems with subcategorization ambiguities, preposition attachment, and coordinate structure ambiguities.<br/><br/>  Because of these problems, most current probabilistic parsing models use some augmented version of PCFGs,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
